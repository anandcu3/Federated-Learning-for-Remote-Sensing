{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "import glob \n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 2\n",
    "validation_set_size = 0.2\n",
    "min_imgs_per_client = 300\n",
    "federated = True\n",
    "batch_size = 1\n",
    "data_dir = './UCMerced_LandUse/Images'\n",
    "multilabel_excel_file = './multilabels/LandUse_Multilabeled.xlsx'\n",
    "class_names =  np.array([\"airplane\",\"bare-soil\",\"buildings\",\"cars\",\"chaparral\",\"court\",\"dock\",\"field\",\"grass\",\"mobile-home\",\"pavement\",\"sand\",\"sea\",\"ship\",\"tanks\",\"trees\",\"water\"])\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\karam\\anaconda3\\envs\\pysyft2\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<VirtualWorker id:host_0 #objects:0>, <VirtualWorker id:host_1 #objects:0>]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel (multilabel_excel_file)\n",
    "df_label = np.array(df)\n",
    "\n",
    "if federated:\n",
    "    hook = sy.TorchHook(torch)\n",
    "    hosts=[]\n",
    "    for i in range(n_clients):\n",
    "        hosts.append(sy.VirtualWorker(hook, id=\"host_\"+str(i)))\n",
    "    print(hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> [1, 2, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def uncor_selecter(nr_label = 4,min_img = 300):\n",
    "    \"\"\"retrun a list with the least correlated labels \"\"\"\n",
    "    image_perlabel = np.sum(df_label[:,1:],axis= 0)\n",
    "    biggest_label =np.where(np.any([image_perlabel > min_img],axis=0))[0]\n",
    "    #print(biggest_label, image_perlabel[biggest_label])\n",
    "\n",
    "    selected_list = [] \n",
    "    allcor_lost = np.array([0,0,0])\n",
    "    for i in range(0,len(biggest_label)-1):\n",
    "        it = biggest_label[i]\n",
    "        for j in range(i+1,len(biggest_label)):\n",
    "            jt = biggest_label[j]\n",
    "\n",
    "            colxor = np.sum(np.logical_xor(df_label[:,it].astype(bool) , df_label[:,jt].astype(bool) )) -  np.sum(np.logical_and(df_label[:,it], df_label[:,jt]))\n",
    "            allcor_lost = np.vstack((allcor_lost, np.array([colxor,it,jt]))) \n",
    "    sorted_list = allcor_lost[allcor_lost[:,0].argsort()]\n",
    "    selected_list.append(sorted_list[-1,1])\n",
    "    selected_list.append(sorted_list[-1,2])\n",
    "    #print(sorted_list, selected_list)        \n",
    "\n",
    "    while len(selected_list)<nr_label:\n",
    "        biggest_label = np.setdiff1d(biggest_label,np.array(selected_list))\n",
    "        largestxor = 0 \n",
    "        largestind = 0\n",
    "        for i in biggest_label:\n",
    "            overall_xor = 0 \n",
    "            for j in (selected_list):\n",
    "                overall_xor += np.sum(np.logical_xor(df_label[:,i].astype(bool) , df_label[:,j].astype(bool) )) -  np.sum(np.logical_and(df_label[:,i], df_label[:,j]))\n",
    "\n",
    "            if overall_xor >= largestxor:\n",
    "                largestxor = overall_xor\n",
    "                largestind = i\n",
    "\n",
    "        selected_list.append(largestind)\n",
    "    \n",
    "    return selected_list\n",
    "\n",
    "\n",
    "trylist = uncor_selecter()\n",
    "print(type(trylist), trylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sampler_split_for_client(cdata, subset, nr_client= 4, minimum_skew_percentage = .4):\n",
    "    selected_labels = uncor_selecter(nr_client, min_imgs_per_client)\n",
    "    \n",
    "    splitlists = []\n",
    "    for sb in selected_labels:\n",
    "        splitlists.append([])\n",
    "    for i, (data, label) in enumerate(subset):\n",
    "        nplabel = label.numpy()\n",
    "        if np.any(nplabel[selected_labels] == 1):\n",
    "            if random.random() < minimum_skew_percentage:\n",
    "                \n",
    "                flip = np.random.randint(np.sum(nplabel[selected_labels] == 1)) \n",
    "                mask = np.where(nplabel[selected_labels] == 1)[0][flip]\n",
    "                splitlists[mask].append(i)\n",
    "            \n",
    "            else:\n",
    "                flip = np.random.randint(nr_client) \n",
    "                splitlists[flip].append(i)\n",
    "                    \n",
    "        else:\n",
    "            flip = np.random.randint(nr_client) \n",
    "            splitlists[flip].append(i)\n",
    "\n",
    "    \n",
    "    for alist in splitlists:\n",
    "        print(len(alist))\n",
    "    return splitlists\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from natsort import natsorted\n",
    "# Built to handle multilabel dataset vs standard ImageFolder dataset from torchvision\n",
    "class CustomDataSet(Dataset): \n",
    "    def __init__(self, main_dir, transform, labelmat):\n",
    "        self.main_dir = main_dir\n",
    "        self.transforms = transform\n",
    "        self.all_imgs = glob.glob(os.path.join(main_dir, '**/*.tif'), recursive=True)\n",
    "        self.total_imgs = natsorted(self.all_imgs)\n",
    "        self.xlabels = labelmat\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = self.total_imgs[idx]\n",
    "        imagebaselabel = os.path.splitext(os.path.basename(img_loc))[0]\n",
    "        label = self.xlabels[np.where(self.xlabels[:,0] == imagebaselabel),1:].reshape(17).astype(np.int64)\n",
    "        tensor_label =  torch.from_numpy(label)\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transforms(image)\n",
    "        return tensor_image, tensor_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFromSubset(Dataset):\n",
    "    \"\"\"\n",
    "    Helper to convert subsets to datasets since PySyft only works with the datasets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, subset):\n",
    "        data, targets = self.subset_to_dataset(subset)\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index, :], self.targets[index]\n",
    "\n",
    "    @staticmethod\n",
    "    def subset_to_dataset(subset):\n",
    "        \"\"\"\n",
    "        Method to turn the index tensor and original dataset in subsets into smaller datasets\n",
    "        :param subset: Subset to transform\n",
    "        :return: dataset\n",
    "        \"\"\"\n",
    "        indices = subset.indices\n",
    "        targets = subset.dataset.dataset.xlabels\n",
    "\n",
    "        if isinstance(indices, list):\n",
    "            pass\n",
    "        elif isinstance(indices, torch.tensor):\n",
    "            indices = list(indices.data.numpy())\n",
    "        elif isinstance(indices, np.ndarray):\n",
    "            indices = list(indices)\n",
    "\n",
    "        else:\n",
    "            print(type(indices))\n",
    "            raise NotImplementedError\n",
    "\n",
    "        dataloader = torch.utils.data.DataLoader(subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        for ii, (data, target) in enumerate(dataloader):\n",
    "            #del target\n",
    "            if ii == 0:\n",
    "                concat_tensor = data\n",
    "                targets_subset = target\n",
    "            else:\n",
    "                concat_tensor = torch.cat((concat_tensor, data), 0)\n",
    "                targets_subset = torch.cat((targets_subset, target), 0)\n",
    "\n",
    "        return concat_tensor, targets_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_test(datadir, labelmat,valid_size = .2):\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    loaded_dataset = CustomDataSet(datadir, transform=train_transforms, labelmat=labelmat)\n",
    "    #loaded_dataset = datasets.ImageFolder(data_dir)\n",
    "    total_dataset_size = len(loaded_dataset)\n",
    "    split = int(np.floor(valid_size * total_dataset_size))\n",
    "    valid_set = torch.utils.data.Subset(loaded_dataset, range(split))  # take first 10%\n",
    "    train_set = torch.utils.data.Subset(loaded_dataset, range(split, total_dataset_size))  # take the rest  \n",
    "    if federated:\n",
    "        train_set_splits = sampler_split_for_client(loaded_dataset, train_set, n_clients)\n",
    "        train_set = [DatasetFromSubset(torch.utils.data.Subset(train_set,split)) for split in train_set_splits]\n",
    "    \n",
    "    return train_set, valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847\n",
      "833\n",
      "{'train': [((Wrapper)>[PointerTensor | me:64635612162 -> host_0:42429593629], (Wrapper)>[PointerTensor | me:39578794506 -> host_0:59656446538]), ((Wrapper)>[PointerTensor | me:3765643063 -> host_1:96018850718], (Wrapper)>[PointerTensor | me:85000246450 -> host_1:99322805923])], 'val': <torch.utils.data.dataset.Subset object at 0x0000025C8CC56748>}\n"
     ]
    }
   ],
   "source": [
    "train_set, valid_set = load_split_train_test(data_dir, df_label, validation_set_size)\n",
    "\n",
    "if federated:\n",
    "    assert len(train_set) == len(hosts), \"The number of clients and data partitions do not match.\"\n",
    "    federated_train_loader = []\n",
    "    for i in range(n_clients):\n",
    "        # Create pointers\n",
    "        data_pointer = train_set[i].data.send(hosts[i])\n",
    "        target_pointer = train_set[i].targets.send(hosts[i])\n",
    "        federated_train_loader.append((data_pointer, target_pointer))\n",
    "    dataloaders = {\"train\" : federated_train_loader, \"val\" : valid_set}\n",
    "else:\n",
    "    dataloaders = {\"train\" : train_set, \"val\" : valid_set}\n",
    "print(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        from collections import OrderedDict\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(5, 5))\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(5, 5))\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(5, 5))\n",
    "        #self.conv4 = nn.Conv2d(64, 128, kernel_size=(5, 5))\n",
    "        self.linear1 = nn.Linear(64 * 24 * 24, 120)\n",
    "        self.linear2 = nn.Linear(120, 84)\n",
    "        self.linear3 = nn.Linear(84, n_classes)                                \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Input images.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (batch_size, 10): Outputs of the network.\n",
    "        \"\"\"\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), kernel_size=2, stride=2)\n",
    "        #x = F.max_pool2d(F.relu(self.conv4(x)), kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 64 * 24 * 24)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=5, batch_size=4):\n",
    "    %matplotlib inline\n",
    "    import pylab as pl\n",
    "    from IPython import display\n",
    "    def live_plot(data):\n",
    "        pl.plot(data)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    loss_values, loss_values_val, accuracy_values_val = [], [], []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        model.train()  # Set model to training mode\n",
    "        losses_clients = []\n",
    "\n",
    "        # Iterate over data.\n",
    "        for i, (inputs, labels) in enumerate(tqdm(dataloaders['train'])):\n",
    "            if federated:\n",
    "                model.send(inputs.location)\n",
    "                \n",
    "            print(\"label\", labels)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #_, preds = torch.max(outputs, 1)\n",
    "            outputcpu = outputs.cpu()\n",
    "            preds = np.heaviside(outputcpu.detach().numpy(),0)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            print(\"loss\", loss)\n",
    "\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if federated:\n",
    "                # get model (with gradients)\n",
    "                model.get()\n",
    "                loss.get()\n",
    "                \n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    output.item(),\n",
    "                ))\n",
    "            losses_clients.append(output.item())\n",
    "        epoch_loss_train = sum(losses_clients)/n_clients\n",
    "        loss_values.append(epoch_loss_train)\n",
    "        live_plot(loss_values)\n",
    "        print('Train Loss: {:.4f} Train Acc: {:.4f}'.format(epoch_loss_train))\n",
    "\n",
    "        model.eval()   # Set model to evaluate mode\n",
    "        for i, (inputs, labels) in enumerate(tqdm(dataloaders['val'])):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            #_, preds = torch.max(outputs, 1)\n",
    "            outputcpu = outputs.cpu()\n",
    "            preds = np.heaviside(outputcpu.detach().numpy(),0)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss_val += loss.get()\n",
    "            running_corrects_val += torch.sum(preds == labels.data).get()\n",
    "          \n",
    "        epoch_loss_val = running_loss_val / len(dataloaders['val'])\n",
    "        epoch_acc_val = running_corrects_val / len(dataloaders['val'])\n",
    "        loss_values_val.append(epoch_loss_val)\n",
    "        accuracy_values_val.append(epoch_acc_val)\n",
    "        print('Val Loss: {:.4f} Val Acc: {:.4f}'.format(epoch_loss_val, epoch_acc_val))\n",
    "\n",
    "        # deep copy the model\n",
    "        if epoch_acc_val > best_acc:\n",
    "            best_acc = epoch_acc_val\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    #print(loss_values, accuracy_values, loss_values_val, accuracy_values_val)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, {\"tloss\":loss_values, \"valloss\":loss_values_val, \"tacc\":accuracy_values,\"valacc\":accuracy_values_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31a388aa6f949228845043a82e0fd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf827f00c95b4f0ab7530ba7611cc7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label (Wrapper)>[PointerTensor | me:39578794506 -> host_0:59656446538]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "model = CNN(len(class_names))\n",
    "model = model.to(device)\n",
    "#model_ft = models.resnet18(pretrained=False)\n",
    "#num_ftrs = model_ft.fc.in_features\n",
    "#model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "#model = model_ft.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model, stats_dict = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, num_epochs=25, batch_size=batch_size)\n",
    "#torch.save(model.state_dict(), \"resnet_fl2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
