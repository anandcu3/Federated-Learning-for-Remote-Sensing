{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "import glob \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel ('./multilabels/new_LandUse_Multilabeled.xlsx')\n",
    "df_label = np.array(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names =  np.array([\"airplane\",\"bare-soil\",\"buildings\",\"cars\",\"chaparral\",\"court\",\"dock\",\"field\",\"grass\",\"mobile-home\",\"pavement\",\"sand\",\"sea\",\"ship\",\"tanks\",\"trees\",\"water\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = df_label[:,1:]\n",
    "\n",
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "\n",
    "model = model.fit(X)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plot the top three levels of the dendrogram\n",
    "plot_dendrogram(model, truncate_mode='level', p=3)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674 bare-soil cars (2, 4)\n"
     ]
    }
   ],
   "source": [
    "largestxor = 0 \n",
    "largestij = (0,0)\n",
    "\n",
    "for i in range(1,17):\n",
    "    for j in range(i+1,18):\n",
    "        #colnand = np.sum(np.logical_not(np.logical_and(df_label[:,i], df_label[:,j])))\n",
    "        colxor = np.sum(np.logical_xor(df_label[:,i].astype(bool) , df_label[:,j].astype(bool) )) -  np.sum(np.logical_and(df_label[:,i], df_label[:,j]))\n",
    "        #print(i,j, colxor, colnand)\n",
    "        if colxor >= largestxor and np.sum(df_label[:,i]) >=700 and np.sum(df_label[:,j])>= 700 :\n",
    "            largestxor = colxor\n",
    "            largestij = (i,j)\n",
    "print(largestxor,class_names[largestij[0]-1], class_names[largestij[1]-1], largestij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  8 10 15] [718 691 886 975 1300 1009]\n",
      "<class 'list'> [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "def uncor_selecter(nr_label = 4,min_img = 300):\n",
    "    \"\"\"retrun a list with the least correlated labels \"\"\"\n",
    "    image_perlabel = np.sum(df_label[:,1:],axis= 0)\n",
    "    biggest_label =np.where(np.any([image_perlabel > min_img],axis=0))[0]\n",
    "    print(biggest_label, image_perlabel[biggest_label])\n",
    "\n",
    "    selected_list = [] \n",
    "    allcor_lost = np.array([0,0,0])\n",
    "    for i in range(0,len(biggest_label)-1):\n",
    "        it = biggest_label[i]\n",
    "        for j in range(i+1,len(biggest_label)):\n",
    "            jt = biggest_label[j]\n",
    "\n",
    "            colxor = np.sum(np.logical_xor(df_label[:,it].astype(bool) , df_label[:,jt].astype(bool) )) -  np.sum(np.logical_and(df_label[:,it], df_label[:,jt]))\n",
    "            allcor_lost = np.vstack((allcor_lost, np.array([colxor,it,jt]))) \n",
    "    sorted_list = allcor_lost[allcor_lost[:,0].argsort()]\n",
    "    selected_list.append(sorted_list[-1,1])\n",
    "    selected_list.append(sorted_list[-1,2])\n",
    "    #print(sorted_list, selected_list)        \n",
    "\n",
    "    while len(selected_list)<nr_label:\n",
    "        biggest_label = np.setdiff1d(biggest_label,np.array(selected_list))\n",
    "        largestxor = 0 \n",
    "        largestind = 0\n",
    "        for i in biggest_label:\n",
    "            overall_xor = 0 \n",
    "            for j in (selected_list):\n",
    "                overall_xor += np.sum(np.logical_xor(df_label[:,i].astype(bool) , df_label[:,j].astype(bool) )) -  np.sum(np.logical_and(df_label[:,i], df_label[:,j]))\n",
    "\n",
    "            if overall_xor >= largestxor:\n",
    "                largestxor = overall_xor\n",
    "                largestind = i\n",
    "\n",
    "        selected_list.append(largestind)\n",
    "    \n",
    "    return selected_list\n",
    "\n",
    "\n",
    "trylist = uncor_selecter(3, 300)\n",
    "print(type(trylist), trylist)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sampler_split_for_client(cdata, idxs, nr_client= 4, minimum_skew_percentage = .4):\n",
    "    selected_labels = uncor_selecter(nr_client,300)\n",
    "    \n",
    "    splitlists = []\n",
    "    for sb in selected_labels:\n",
    "        splitlists.append([])\n",
    "        \n",
    "    \n",
    "    for i in idxs:\n",
    "        nplabel = cdata.__getlabel__(i)\n",
    "        #nplabel = label.numpy()\n",
    "        \n",
    "        if np.any(nplabel[selected_labels] == 1):\n",
    "            if random.random() < minimum_skew_percentage:\n",
    "                \n",
    "                flip = np.random.randint(np.sum(nplabel[selected_labels] == 1)) \n",
    "                mask = np.where(nplabel[selected_labels] == 1)[0][flip]\n",
    "                splitlists[mask].append(i)\n",
    "            \n",
    "            else:\n",
    "                flip = np.random.randint(nr_client) \n",
    "                splitlists[flip].append(i)\n",
    "                    \n",
    "        else:\n",
    "            flip = np.random.randint(nr_client) \n",
    "            splitlists[flip].append(i)\n",
    "\n",
    "    \n",
    "    for alist in splitlists:\n",
    "        print(len(alist))\n",
    "    return splitlists\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from natsort import natsorted\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, transform, labelmat):\n",
    "        self.main_dir = main_dir\n",
    "        self.transforms = transform\n",
    "        self.all_imgs = glob.glob(os.path.join(main_dir, '**/*.tif'), recursive=True)\n",
    "        self.total_imgs = natsorted(self.all_imgs)\n",
    "        self.xlabels = labelmat\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx,len(self.total_imgs))\n",
    "        img_loc = self.total_imgs[idx]\n",
    "        #print(img_loc)\n",
    "        imagebaselabel = os.path.splitext(os.path.basename(img_loc))[0]\n",
    "        label = self.xlabels[np.where(self.xlabels[:,0] == imagebaselabel),1:].reshape(17).astype(np.int64)\n",
    "        #print(label,label.shape)\n",
    "        tensor_label =  torch.from_numpy(label)\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transforms(image)\n",
    "        return tensor_image, tensor_label\n",
    "    \n",
    "    def __getlabel__(self, idx):\n",
    "        \n",
    "        img_loc = self.total_imgs[idx]\n",
    "        #print(img_loc)\n",
    "        imagebaselabel = os.path.splitext(os.path.basename(img_loc))[0]\n",
    "        label = self.xlabels[np.where(self.xlabels[:,0] == imagebaselabel),1:].reshape(17).astype(np.int64)\n",
    "        \n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200\n",
      "[ 1  2  3  8 10 11 15 16] [1436 1382 1772 1950 2600 588 2018 406]\n",
      "576\n",
      "547\n",
      "557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_dir = './UCMerced_LandUse/images'\n",
    "def load_split_train_test(datadir, labelmat,valid_size = .2):\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_data = CustomDataSet(datadir, transform=train_transforms, labelmat=labelmat)\n",
    "    test_data = CustomDataSet(datadir, transform=train_transforms, labelmat=labelmat)\n",
    "    print(train_data.__len__())\n",
    "    indices = list(range(2100))\n",
    "    split = int(np.floor(valid_size * 2100))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    \n",
    "    \n",
    "    lists = sampler_split_for_client(train_data, train_idx,3,.4)\n",
    "    \n",
    "    \n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=4)     \n",
    "    \n",
    "    client_loaders = []\n",
    "    for indlist in lists:\n",
    "        train_sampler = SubsetRandomSampler(indlist)\n",
    "        trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=4)\n",
    "        \n",
    "        client_loaders.append(trainloader)\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    return client_loaders,testloader\n",
    "trainloaders, valloader  = load_split_train_test(data_dir, df_label,.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=1, phase = 'train'):\n",
    "    tloss, tacc= [] , []\n",
    "    vloss, vacc= [] , []\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    #best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        if True:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    #_, preds = torch.max(outputs, 1)\n",
    "                    outputcpu = outputs.cpu()\n",
    "                    preds = np.heaviside(outputcpu.detach().numpy(),0)\n",
    "                    #print(outputs, preds)\n",
    "                    loss = criterion(outputs, labels.type(torch.float))\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                    #outputsnp = outputs.cpu().numpy()\n",
    "                    #preds = np.array(outputsnp > 0.5, dtype=float)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += ((torch.sum(torch.from_numpy(preds).to(device) == labels.data)).item() / len(class_names))\n",
    "                #print(\"running_corrects\",running_corrects)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders.dataset)\n",
    "            epoch_acc = (running_corrects) / len(dataloaders.dataset)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                tloss.append(epoch_loss)\n",
    "                tacc.append(epoch_acc)\n",
    "            \n",
    "            if phase == 'val':\n",
    "                vloss.append(epoch_loss)\n",
    "                vacc.append(epoch_acc)\n",
    "            \n",
    "            #print(dataset_sizes[phase],epoch_acc)\n",
    "            #print(type(epoch_loss),type(epoch_acc))\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    return copy.deepcopy(model),[tloss,tacc,vloss,vacc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LENET(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(LENET, self).__init__()\n",
    "        from collections import OrderedDict\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(5, 5))\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(5, 5))\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(5, 5))\n",
    "        #self.conv4 = nn.Conv2d(64, 128, kernel_size=(5, 5))\n",
    "        self.linear1 = nn.Linear(64 * 24 * 24, 120)\n",
    "        self.linear2 = nn.Linear(120, 84)\n",
    "        self.linear3 = nn.Linear(84, n_classes)                                \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Input images.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (batch_size, 10): Outputs of the network.\n",
    "        \"\"\"\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), kernel_size=2, stride=2)\n",
    "        #x = F.max_pool2d(F.relu(self.conv4(x)), kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 64 * 24 * 24)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LENET(len(class_names))\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet34(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model = model_ft.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch numero 0\n",
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 0.1005 Acc: 0.0738\n",
      "Training complete in 0m 11s\n",
      "Done with clientelo numero whateva [[0.10045717381295703], [0.07378151260504208], [], []]\n",
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 0.0968 Acc: 0.0704\n",
      "Training complete in 0m 10s\n",
      "Done with clientelo numero whateva [[0.09675327520994913], [0.07043417366946779], [], []]\n",
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 0.0990 Acc: 0.0708\n",
      "Training complete in 0m 11s\n",
      "Done with clientelo numero whateva [[0.098967877356779], [0.07078431372549018], [], []]\n",
      "Epoch 0/0\n",
      "----------\n",
      "val Loss: 0.0714 Acc: 0.0568\n",
      "Training complete in 0m 11s\n",
      "Done with validation [[], [], [0.07143048797334943], [0.05684873949579834]]\n"
     ]
    }
   ],
   "source": [
    "def train_fedavg_model(model, device, clients, optimizer, criterion, scheduler, c_fraction, epochs=10):\n",
    "    # iterate through epochs\n",
    "    for i in range(epochs):\n",
    "        # get random subset of clients\n",
    "        #fraction = int( c_fraction * float(len(clients_t)) )\n",
    "        #client_subset = random.sample(clients, fraction)\n",
    "        \n",
    "        # train each of the clients\n",
    "        models_client_list = []\n",
    "        print(\"Running epoch numero \" + str(i))\n",
    "        for dataloaders in clients:\n",
    "            model_for_client = copy.deepcopy(model)\n",
    "            client_model, statistics = train_model(model_for_client, dataloaders, criterion, optimizer, scheduler, num_epochs=1, phase = 'train')\n",
    "            models_client_list.append(client_model)\n",
    "            print(\"Done with clientelo numero whateva\", statistics)\n",
    "        \n",
    "        # still need to average \n",
    "        # average clients params\n",
    "        # model = sum(k for 1 - num_clients): ( data_client / total_num_data ) * model_client_k\n",
    "        \n",
    "        _, statistics = train_model(model, valloader, criterion, optimizer, scheduler, num_epochs=1, phase = 'val')\n",
    "        print(\"Done with validation\", statistics)\n",
    "\n",
    "        \n",
    "    return 0\n",
    "\n",
    "C_FRACTION = 0.7\n",
    "model = train_fedavg_model(model, device, trainloaders, optimizer_ft, criterion, exp_lr_scheduler, C_FRACTION, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
