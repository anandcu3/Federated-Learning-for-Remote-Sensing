{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "import glob \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\karam\\anaconda3\\envs\\pysyft2\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel ('./multilabels/LandUse_Multilabeled.xlsx')\n",
    "df_label = np.array(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names =  np.array([\"airplane\",\"bare-soil\",\"buildings\",\"cars\",\"chaparral\",\"court\",\"dock\",\"field\",\"grass\",\"mobile-home\",\"pavement\",\"sand\",\"sea\",\"ship\",\"tanks\",\"trees\",\"water\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674 bare-soil cars (2, 4)\n"
     ]
    }
   ],
   "source": [
    "largestxor = 0 \n",
    "largestij = (0,0)\n",
    "\n",
    "for i in range(1,17):\n",
    "    for j in range(i+1,18):\n",
    "        #colnand = np.sum(np.logical_not(np.logical_and(df_label[:,i], df_label[:,j])))\n",
    "        colxor = np.sum(np.logical_xor(df_label[:,i].astype(bool) , df_label[:,j].astype(bool) )) -  np.sum(np.logical_and(df_label[:,i], df_label[:,j]))\n",
    "        #print(i,j, colxor, colnand)\n",
    "        if colxor >= largestxor and np.sum(df_label[:,i]) >=700 and np.sum(df_label[:,j])>= 700 :\n",
    "            largestxor = colxor\n",
    "            largestij = (i,j)\n",
    "print(largestxor,class_names[largestij[0]-1], class_names[largestij[1]-1], largestij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> [1, 2, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "def uncor_selecter(nr_label = 4,min_img = 300):\n",
    "    \"\"\"retrun a list with the least correlated labels \"\"\"\n",
    "    image_perlabel = np.sum(df_label[:,1:],axis= 0)\n",
    "    biggest_label =np.where(np.any([image_perlabel > min_img],axis=0))[0]\n",
    "    #print(biggest_label, image_perlabel[biggest_label])\n",
    "\n",
    "    selected_list = [] \n",
    "    allcor_lost = np.array([0,0,0])\n",
    "    for i in range(0,len(biggest_label)-1):\n",
    "        it = biggest_label[i]\n",
    "        for j in range(i+1,len(biggest_label)):\n",
    "            jt = biggest_label[j]\n",
    "\n",
    "            colxor = np.sum(np.logical_xor(df_label[:,it].astype(bool) , df_label[:,jt].astype(bool) )) -  np.sum(np.logical_and(df_label[:,it], df_label[:,jt]))\n",
    "            allcor_lost = np.vstack((allcor_lost, np.array([colxor,it,jt]))) \n",
    "    sorted_list = allcor_lost[allcor_lost[:,0].argsort()]\n",
    "    selected_list.append(sorted_list[-1,1])\n",
    "    selected_list.append(sorted_list[-1,2])\n",
    "    #print(sorted_list, selected_list)        \n",
    "\n",
    "    while len(selected_list)<nr_label:\n",
    "        biggest_label = np.setdiff1d(biggest_label,np.array(selected_list))\n",
    "        largestxor = 0 \n",
    "        largestind = 0\n",
    "        for i in biggest_label:\n",
    "            overall_xor = 0 \n",
    "            for j in (selected_list):\n",
    "                overall_xor += np.sum(np.logical_xor(df_label[:,i].astype(bool) , df_label[:,j].astype(bool) )) -  np.sum(np.logical_and(df_label[:,i], df_label[:,j]))\n",
    "\n",
    "            if overall_xor >= largestxor:\n",
    "                largestxor = overall_xor\n",
    "                largestind = i\n",
    "\n",
    "        selected_list.append(largestind)\n",
    "    \n",
    "    return selected_list\n",
    "\n",
    "\n",
    "trylist = uncor_selecter()\n",
    "print(type(trylist), trylist)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sampler_split_for_client(cdata, idxs, nr_client= 4, minimum_skew_percentage = .4):\n",
    "    selected_labels = uncor_selecter(nr_client,300)\n",
    "    \n",
    "    splitlists = []\n",
    "    for sb in selected_labels:\n",
    "        splitlists.append([])\n",
    "        \n",
    "    \n",
    "    for i in idxs:\n",
    "        nplabel = cdata.__getlabel__(i)\n",
    "        #nplabel = label.numpy()\n",
    "        \n",
    "        if np.any(nplabel[selected_labels] == 1):\n",
    "            if random.random() < minimum_skew_percentage:\n",
    "                \n",
    "                flip = np.random.randint(np.sum(nplabel[selected_labels] == 1)) \n",
    "                mask = np.where(nplabel[selected_labels] == 1)[0][flip]\n",
    "                splitlists[mask].append(i)\n",
    "            \n",
    "            else:\n",
    "                flip = np.random.randint(nr_client) \n",
    "                splitlists[flip].append(i)\n",
    "                    \n",
    "        else:\n",
    "            flip = np.random.randint(nr_client) \n",
    "            splitlists[flip].append(i)\n",
    "\n",
    "    \n",
    "    for alist in splitlists:\n",
    "        print(len(alist))\n",
    "    return splitlists\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from natsort import natsorted\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, transform, labelmat):\n",
    "        self.main_dir = main_dir\n",
    "        self.transforms = transform\n",
    "        self.all_imgs = glob.glob(os.path.join(main_dir, '**/*.tif'), recursive=True)\n",
    "        self.total_imgs = natsorted(self.all_imgs)\n",
    "        self.xlabels = labelmat\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx,len(self.total_imgs))\n",
    "        img_loc = self.total_imgs[idx]\n",
    "        #print(img_loc)\n",
    "        imagebaselabel = os.path.splitext(os.path.basename(img_loc))[0]\n",
    "        label = self.xlabels[np.where(self.xlabels[:,0] == imagebaselabel),1:].reshape(17).astype(np.int64)\n",
    "        #print(label,label.shape)\n",
    "        tensor_label =  torch.from_numpy(label)\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transforms(image)\n",
    "        return tensor_image, tensor_label\n",
    "    \n",
    "    def __getlabel__(self, idx):\n",
    "        \n",
    "        img_loc = self.total_imgs[idx]\n",
    "        #print(img_loc)\n",
    "        imagebaselabel = os.path.splitext(os.path.basename(img_loc))[0]\n",
    "        label = self.xlabels[np.where(self.xlabels[:,0] == imagebaselabel),1:].reshape(17).astype(np.int64)\n",
    "        \n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554\n",
      "506\n",
      "620\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_dir = './UCMerced_LandUse/images'\n",
    "def load_split_train_test(datadir, labelmat,valid_size = .2):\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_data = CustomDataSet(datadir, transform=train_transforms, labelmat=labelmat)\n",
    "    test_data = CustomDataSet(datadir, transform=train_transforms, labelmat=labelmat)\n",
    "\n",
    "    indices = list(range(2100))\n",
    "    split = int(np.floor(valid_size * 2100))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    \n",
    "    \n",
    "    lists = sampler_split_for_client(train_data, train_idx,3,.4)\n",
    "    \n",
    "    return lists\n",
    "splitlist  = load_split_train_test(data_dir, df_label,.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
